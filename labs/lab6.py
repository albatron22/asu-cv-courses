import marimo

__generated_with = "0.16.0"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    # Л6: Обработка движущихся объектов в OpenCV

    **CV (Computer Vision)**, или *машинное зрение*, — это область искусственного интеллекта, которая занимается разработкой алгоритмов и методов, позволяющих компьютерам "видеть" и интерпретировать изображения и видео. Основная задача компьютерного зрения — автоматическое извлечение полезной информации из визуальных данных, например, распознавание объектов, определение их местоположения или анализ сцен. Это может включать такие приложения, как автоматизация вождения, распознавание лиц и обработка медицинских изображений.

    **OpenCV (Open Source Computer Vision Library)** — библиотека алгоритмов компьютерного зрения, обработки изображений и численных алгоритмов общего назначения с открытым кодом
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ☝️ПОРЯДОК ВЫПОЛНЕНИЯ

    ЛР выполняется последователньно. По мере продвижения по работе вы будете получать задания для закрепления прочитанной теории

    ✏️ **ЗАДАНИЕ 1.**
    ✏️ **ЗАДАНИЕ 2.** и т.д.

    Для каждого задания создается отдельный скрипт Python. Всего заданий будет 4. В качестве отчета необходимо предоставить файлы кода для каждого задания. Отчет закреплять на moodle.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 1/ Подготовка среды выполнения
    На данной этапе вам наобходимо подготовить виртуальное окружение и установить все необходимые библиотеки.

    1. Создать и активировать (или только активировать, если ранне создавали) виртуальной окружение `python`.

    Создайте на диске свою раюочую папку. Откройте терминал и перейдите в свою рабочую директорию
    ```
    cd path/to/your/workspace
    ```
    Далее создаем виртуальное окружение с помощью `python-venv`
    ```
    python -m venv env
    ```
    *активируем виртуальное окружение*
    для CMD:
    ```
    env\Scripts\activate
    ```
    для PowerShell
    ```
    env\Scripts\Activate.ps1
    ```
    для bash
    ```
    source env/bin/activate
    ```
    **Примечание.** `env` - это название вашего виртуального окружения, назвать его можете как угодно.

    После этого можем выбрать наш локальный интерпрететор pyhton, нажав на кнопку выше "Select kernel".

    1. Устанавливаем все необходимые библиотеки

    **Примечание.** Библиотеки установятся внутрь вашего виртуального окружения.

    Нам понадобятся `opencv-python`.
    ```
    pip install opencv-python
    ```
    И `marimo` для для просмотра интерактивной лабораторной работы
    ```
    pip install marimo
    ```
    _но вы должны были ее установить уже до открытия этого приложения_
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 2/ Получение видеопотока

    Вы можете использовать три варианта получения видеопотока: **со встроенной или подключенной камере к вашему ноутбуку, из видеофайла или из локальной сети на занятии в аудитории.**

    /// details | Код для случая видеокамеры или видеофайла
    ```python
    import cv2

    # Захватываем видеопоток с веб-камеры
    cap = cv2.VideoCapture(0)
    # или из файла
    # cap = cv2.VideoCapture('video.mp4')
    while True:
        # Читаем кадр с камеры
        ret, frame = cap.read()
        # Отображаем кадр на экране
        cv2.imshow('WebCam', frame)
        # Ожидание 1 миллисекунды на проверку нажатия клавиши 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Освобождаем ресурсы после завершения работы
    cap.release()
    # Закрываем все окна
    cv2.destroyAllWindows()
    ```
    ///

    Для получения **видеопотока по локальной сети** необходимо создать UDP сокет и подключится к multicast группе. В главном цикле читается байтовый массив по сокету, который преобразуется в jpeg-кадр. Ниже представлен базоый скрипт клиента получения видеопотока:

    /// details | Код клиента
    ```python
    import socket
    import cv2
    import numpy as np

    # Настройки multicast
    MCAST_GRP = '239.1.1.1'
    MCAST_PORT = 5007

    ############### ВМЕСТО cap = cv2.VideoCapture(0) ####################
    #####################################################################
    # Создаем UDP сокет
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

    # Присоединяемся к multicast группе
    sock.bind(('', MCAST_PORT))
    mreq = socket.inet_aton(MCAST_GRP) + socket.inet_aton('0.0.0.0')
    sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
    #####################################################################

    # Главный цикл
    while True:
    ############### ВМЕСТО ret, frame = cap.read() ######################
    #####################################################################
        # Получаем данные
        data, addr = sock.recvfrom(65536)  # Макс размер UDP пакета

        # Декодируем JPEG в изображение
        nparr = np.frombuffer(data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    #####################################################################

        if frame is not None:s
            cv2.imshow('Multicast Stream', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cv2.destroyAllWindows()
    sock.close()
    ```
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 3/ **Основы обработки движущихся объектов**

    Обработка движущихся объектов является важной частью компьютерного зрения, предоставляя машинам возможность автоматически обнаруживать и отслеживать движущиеся объекты на изображениях и видеопотоках. Этот процесс находит широкое применение в реальном мире, включая области видеонаблюдения, автоматизации и робототехники.

    Важность обработки движущихся объектов проявляется в способности системы следить за динамикой сцен, что делает ее эффективной в решении различных задач. Обнаружение движущихся объектов фокусируется на выявлении их присутствия на изображении, в то время как отслеживание позволяет системе отслеживать перемещение объекта в пространстве со временем. Эти два процесса в сочетании позволяют системам реагировать на изменения в реальном времени.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Обработка движущихся объектов охватывает ключевые концепции, такие как обнаружение и отслеживание, и их роль в создании более интеллектуальных систем компьютерного зрения.

    Обработка движущихся объектов в компьютерном зрении представляет собой обширный набор методов и техник, предназначенных для обнаружения, отслеживания и анализа движущихся объектов в видеопотоках или на изображениях. Основные подходы включают в себя вычитание фона, оптический поток, детекторы движения, методы машинного обучения, алгоритмы отслеживания объектов, сегментацию кадра и глубокое обучение.

    Метод вычитания фона используется для выделения объектов путем вычитания статического фона из текущего кадра, а оптический поток измеряет движение пикселей между последовательными кадрами. Детекторы движения выделяют области, где происходят изменения на изображении, а методы машинного обучения, такие как SVM и нейронные сети, могут классифицировать и анализировать движущиеся объекты.

    Алгоритмы отслеживания объектов, такие как корреляция и фильтры Калмана, позволяют системе отслеживать движущиеся объекты через несколько кадров. Сегментация кадра используется для выделения объектов на изображении, что упрощает их последующее отслеживание. Глубокое обучение, особенно сверточные нейронные сети, применяется для более точного обнаружения и классификации движущихся объектов.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### 3.1/ **Предварительная обработка изображений**

    Этот этап нацелен на улучшение качества изображений, повышение их контрастности, снижение шума и обеспечение более оптимального входа для алгоритмов обнаружения и отслеживания движущихся объектов.

    Одной из ключевых задач предварительной обработки является фильтрация шума. Применение методов сглаживания, таких как Гауссовский или медианный фильтр, помогает уменьшить случайные изменения яркости пикселей, что может негативно сказываться на точности обработки.

    Также может быть полезным преобразование цветового пространства, например, с помощью `cv2.cvtColor`.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Рассмотрим пример кода, в котором поэтапно будем наслаивать дополнительные фукнции. Наща задача заключается в **отслеживании движения указанного объекта**.

    На этапе предварителньо обработки применим преобразование цветового пространства и фильтрацию.

    ```python
    import cv2

    # Загрузка видеопотока с веб-камеры
    cap = cv2.VideoCapture(0)

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Преобразование в оттенки серого
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # Размытие для сглаживания изображения и уменьшения шума
        filter_frame = cv2.GaussianBlur(gray, (5, 5), 0)
        cv2.imshow('Tracking', filter_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    ```
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    **Преобразование в оттенки серого:**

    `gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)`. Этот метод преобразует цветное изображение в оттенки серого, что уменьшает количество каналов (вместо трех каналов, один) и облегчает последующую обработку. Кроме того, для многих задач обработки изображений, таких как выделение контуров, обнаружение объектов или распознавание объектов, информация о цвете может быть не так важна, как информация о яркости. Поэтому преобразование в оттенки серого позволяет упростить алгоритмы обработки и ускорить их выполнение.

    **Размытие для сглаживания изображения и уменьшения шума:**

    `blurred = cv2.GaussianBlur(gray, (5, 5), 0)` Здесь используется гауссовское размытие (GaussianBlur) для сглаживания изображения и уменьшения шума. Этот метод применяет фильтр Гаусса к каждому пикселю, что создает эффект размытия и помогает сгладить изображение. Таким образом, применение гауссовского размытия перед обработкой движущихся объектов помогает улучшить качество изображения и сделать последующую обработку более эффективной и надежной.

    Количество предлагаемых фильтров в библиотеке OpenCV немало. И в лучшем случае следует вывести результаты нескольких фильтров, чтобы выбрать тот, который отвечает данным требованиям задачи.
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    /// admonition | ✏️ **ЗАДАНИЕ 1.**
    Максимально улучшить изображение с вашей вебкамеры путем применения эксперимента с разлчиными фильтрами (используйте знания из ЛР №4)
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### 3.2/ **Выбор области интереса**

    Выбор области интереса **(Region of Interest, ROI)** в контексте отслеживания объекта в компьютерном зрении представляет собой процесс выделения определенной области изображения, которая содержит интересующий нас объект.

    ROI имеет большое значение для эффективного отслеживания объектов, так как позволяет сосредоточить вычислительные ресурсы (процессорное время, память) на анализе только той части изображения, где находится интересующий объект.

    Процесс выбора области интереса может быть выполнен как вручную, так и автоматически. В случае ручного выбора, пользователь определяет область интереса вручную, указывая границы объекта на изображении, например, с помощью прямоугольника, многоугольника или маски. В автоматическом режиме алгоритмы компьютерного зрения могут использоваться для обнаружения и выделения объекта, основываясь на признаках, таких как цвет, текстура, форма. Ниже представлн рисунок, поясняющий ROI.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""![](public\image_roi.png)""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Оптимальный размер ROI зависит от конкретных условий задачи, характеристик объекта и требований к производительности системы. Эксперименты и настройка параметров обычно требуются для достижения оптимального баланса между вычислительной эффективностью и точностью отслеживания.

    Напомним, что изображение на экране с размером, например, 1280×720 является не чем иным, как матрицей пикселей с размером 1280 пикселей по горизонтали и 720 пикселей по вертикали. То есть все изображения имеет математическую запись на языке Python: `a = frame[0:720, 0:1280]` или более компактная запись `a = frame[:720, :1280]`.

    Таким же математическим трюком можно и выделить область ROI, например, `roi = frame[200:250, 150:300]`. Этой записью мы выделяем фрагмент кадра, ограниченный прямоугольником. Интервал `200:250` означает, что мы берем вертикальные пиксели с 200-го по 249-й включительно. Таким образом, это представляет 50 вертикальных пикселей. А интервал `150:300` означает, что мы берем горизонтальные пиксели с 150-го по 299-й включительно. Таким образом, это представляет 150 горизонтальных пикселей.

    Итак, ROI будет состоять из 50 вертикальных строк (пикселей) и 150 горизонтальных столбцов (пикселей), образуя прямоугольную область изображения. На рис. ниже приведено графическое пояснение создания области ROI.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    _**Выделение ROI в кадре**_

    ![](public\image_roi1.png)
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Рассмотрим пример программы, в которой область интересов ROI имеет фиксированный размер 280х200.

    ```python
    import cv2
    cap = cv2.VideoCapture(0)

    while True:
        ret, frame = cap.read()
        # Определяем область ROI
        roi = frame[120:400, 200:400]
        # Переносим область интереса в серые цвета
        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        # Переносим область интереса в BGR
        gray_roi = cv2.cvtColor(gray_roi, cv2.COLOR_GRAY2BGR)
        # Перекрашиваем в оттенки серого выделенный фрагмент кадра
        frame[120:400, 200:400] = gray_roi
        cv2.rectangle(frame, (230, 150), (350, 350), (0, 255, 0), 2)
        cv2.imshow('Otslejivanie', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    ```

    **Пояснение:**

    Первое преобразование `cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)` переводит изображение из цветной области BGR в область оттенков серого. Второе преобразование `cv2.cvtColor(gray_roi, cv2.COLOR_GRAY2BGR)` переводит изображение из области серых тонов в цветную область BGR, при этом изображение остается серым. Это дает нам возможность применить изображения в оттенках серого в цветной области.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Еще один простой способ выделить область ROI в кадре – это использование функции из библиотеки OpenCV: `cv2.selectROI()`. Эта функция, в отличии от предыдущего метода выбора области ROI, позволяет определить границы области интересов и объект интерактивно. То есть, когда вызывается `cv2.selectROI`, появляется окно с изображением, и пользователь может выделить интересующую его область, перетаскивая мышь и задавая размеры прямоугольника. Эти действия в реальном времени влияют на параметры выбранной области, которые затем возвращаются из функции.

    Такой подход позволяет пользователям взаимодействовать с программой или библиотекой, делая ее более удобной и гибкой в использовании, особенно при работе с визуальными данными, такими как изображения или видео.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// admonition | ✏️ **ЗАДАНИЕ 2.**
    Напишите программы для интераткивного выделения области ROI с помощью функции `cv2.selectROI()`. Разберитесь самостоятельно с документацией на эту функцию и примените ее.
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Форма отчета

    Отчет должен представлять собой программный код для всех заданий и скриншоты экрана, демонстрирующие работоспособоность вашего кода. Отчет загрузить на **moodle**
    """
    )
    return


if __name__ == "__main__":
    app.run()
