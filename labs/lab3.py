import marimo

__generated_with = "0.16.0"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    # Л3: Методы обработки изображений. Работа с кадрами

    **CV (Computer Vision)**, или *машинное зрение*, — это область искусственного интеллекта, которая занимается разработкой алгоритмов и методов, позволяющих компьютерам "видеть" и интерпретировать изображения и видео. Основная задача компьютерного зрения — автоматическое извлечение полезной информации из визуальных данных, например, распознавание объектов, определение их местоположения или анализ сцен. Это может включать такие приложения, как автоматизация вождения, распознавание лиц и обработка медицинских изображений.

    **OpenCV (Open Source Computer Vision Library)** — библиотека алгоритмов компьютерного зрения, обработки изображений и численных алгоритмов общего назначения с открытым кодом
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ☝️ПОРЯДОК ВЫПОЛНЕНИЯ

    ЛР выполняется последователньно. По мере продвижения по работе вы будете получать задания для закрепления прочитанной теории

    ✏️ **ЗАДАНИЕ 1.**
    ✏️ **ЗАДАНИЕ 2.** и т.д.

    Для каждого задания создается отдельный скрипт Python. Всего заданий будет 4. В качестве отчета необходимо предоставить файлы кода для каждого задания. Отчет закреплять на moodle.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 1/ Подготовка среды выполнения
    На данной этапе вам наобходимо подготовить виртуальное окружение и установить все необходимые библиотеки.

    1. Создать и активировать (или только активировать, если ранне создавали) виртуальной окружение `python`.

    Создайте на диске свою раюочую папку. Откройте терминал и перейдите в свою рабочую директорию
    ```
    cd path/to/your/workspace
    ```
    Далее создаем виртуальное окружение с помощью `python-venv`
    ```
    python -m venv env
    ```
    *активируем виртуальное окружение*
    для CMD:
    ```
    env\Scripts\activate
    ```
    для PowerShell
    ```
    env\Scripts\Activate.ps1
    ```
    для bash
    ```
    source env/bin/activate
    ```
    **Примечание.** `env` - это название вашего виртуального окружения, назвать его можете как угодно.

    После этого можем выбрать наш локальный интерпрететор pyhton, нажав на кнопку выше "Select kernel".

    1. Устанавливаем все необходимые библиотеки

    **Примечание.** Библиотеки установятся внутрь вашего виртуального окружения.

    Нам понадобятся `opencv-python`.
    ```
    pip install opencv-python
    ```
    И `marimo` для для просмотра интерактивной лабораторной работы
    ```
    pip install marimo
    ```
    _но вы должны были ее установить уже до открытия этого приложения_
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 2/ Получение видеопотока

    Вы можете использовать три варианта получения видеопотока: **со встроенной или подключенной камере к вашему ноутбуку, из видеофайла или из локальной сети на занятии в аудитории.**

    /// details | Код для случая видеокамеры или видеофайла
    ```python
    import cv2

    # Захватываем видеопоток с веб-камеры
    cap = cv2.VideoCapture(0)
    # или из файла
    # cap = cv2.VideoCapture('video.mp4')
    while True:
        # Читаем кадр с камеры
        ret, frame = cap.read()
        # Отображаем кадр на экране
        cv2.imshow('WebCam', frame)
        # Ожидание 1 миллисекунды на проверку нажатия клавиши 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Освобождаем ресурсы после завершения работы
    cap.release()
    # Закрываем все окна
    cv2.destroyAllWindows()
    ```
    ///

    Для получения **видеопотока по локальной сети** необходимо создать UDP сокет и подключится к multicast группе. В главном цикле читается байтовый массив по сокету, который преобразуется в jpeg-кадр. Ниже представлен базоый скрипт клиента получения видеопотока:

    /// details | Код клиента
    ```python
    import socket
    import cv2
    import numpy as np

    # Настройки multicast
    MCAST_GRP = '239.1.1.1'
    MCAST_PORT = 5007

    ############### ВМЕСТО cap = cv2.VideoCapture(0) ####################
    #####################################################################
    # Создаем UDP сокет
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

    # Присоединяемся к multicast группе
    sock.bind(('', MCAST_PORT))
    mreq = socket.inet_aton(MCAST_GRP) + socket.inet_aton('0.0.0.0')
    sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
    #####################################################################

    # Главный цикл
    while True:
    ############### ВМЕСТО ret, frame = cap.read() ######################
    #####################################################################
        # Получаем данные
        data, addr = sock.recvfrom(65536)  # Макс размер UDP пакета

        # Декодируем JPEG в изображение
        nparr = np.frombuffer(data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    #####################################################################

        if frame is not None:s
            cv2.imshow('Multicast Stream', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cv2.destroyAllWindows()
    sock.close()
    ```
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 3/ **Методы обработки изображений** (продолжение)
    ### 3.1/ **Инверсия цветов**

    **_Инверсия изображения_** — это процесс изменения цветовых значений пикселей изображения на противоположные. Для наглядности можно сказать, что светлые точки становятся темными, а темные — светлыми. В общем случае, цвета меняются на противоположные в соответствии с используемым цветовым пространством.

    Инверсия часто используется для создания интересных визуальных эффектов и дизайнерских решений, придавая изображению необычный вид и выделяя определенные детали. В области медицинской диагностики инверсия может применяться для лучшего выделения и анализа определенных структур в медицинских изображениях, таких как рентгеновские снимки. Также инверсию используют в процессе редактирования фотографий для создания специфических эффектов или коррекции изображений.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Принцип инверсии основан на изменении значений каждого цветового канала пикселя на противоположный. В случае RGB-изображений (красный, зелёный, синий), инверсия достигается путём вычитания значения каждого канала из максимального возможного значения для данного типа данных, обычно 255. Это означает, что, если у пикселя было значение, например, RGB (50, 100, 150), после инверсии оно станет (205, 155, 105). Инверсия применима и к изображениям в оттенках серого, где инверсия также достигается путём вычитания значения яркости из максимального значения.

    Рассмотрим применение инверсии на примере видеопотока. Для реализации инверсии мы воспользуемся функцией `cv2.bitwise_not()`. Ниже представлен код, который демонстрирует применение инверсии для видеопотока, принятого с веб-камеры. Запустите его проверьте результат.

    ```python
    import cv2

    # Захват видеопотока с камеры
    cap = cv2.VideoCapture(0)
    while True:
        # Считывание кадра из видеопотока
        ret, frame = cap.read()
        # Инверсия цветов пикселей в кадре
        inverted_frame = cv2.bitwise_not(frame)
        # Отображение оригинального кадра
        cv2.imshow('Original Frame', frame)
        # Отображение измененного кадра
        cv2.imshow('Modified Frame', inverted_frame)

        # Проверка на нажатие клавиши 'q' для выхода из цикла
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    # Освобождение ресурсов
    cap.release()
    cv2.destroyAllWindows()
    ```
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Вот некоторые примеры применения инверсии в различных областях.

    1. **Фотофильтры**: многие приложения для редактирования фотографий предлагают фильтры, включающие инверсию. Это может придать фотографии необычный и запоминающийся вид.

    2. **Тематические дизайны**: в веб-дизайне или создании постеров инверсия используется для создания тематических эффектов, подчеркивания определенных элементов и привлечения внимания к деталям.

    3. **Медицинская обработка изображений**: в медицинской сфере инверсия может быть полезна для выделения конкретных областей ткани или структур в рамках диагностических процедур.

    4. **Термальное видение в автомобилях**: инверсия может быть применена к изображениям с телевизионных камер. В автомобилях такие камеры используются для обнаружения тепловых источников, таких как транспортные средства или люди, особенно в условиях низкой видимости, например, в ночное время или в условиях тумана. Инверсия может помочь выделить и подчеркнуть тепловые образы, улучшая обнаружение объектов на дороге.

    5. **Обратное видеонаблюдение**: в системах видеонаблюдения на транспортных средствах или на территории автостанций инверсия может быть использована для лучшего выделения объектов и обнаружения необычных событий. Например, при обратном видеонаблюдении темные объекты, такие как пешеходы, могут быть более заметными на светлом фоне.

    6. **Аварийные ситуации**: инверсия может быть применена к изображениям из камер наблюдения для выделения аварийных ситуаций или подозрительных объектов и обстоятельств. Это может помочь операторам транспортных систем быстрее реагировать на потенциально опасные ситуации.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// admonition | ✏️ **ЗАДАНИЕ 1.**
    Напишите программу для инверсии только половины кадра. Изображение разделить кадр по горизонтали или по вертикали
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### 3.2/ **Линейное объединение двух изображений**

    **Линейное объединение двух изображений**— это процесс создания нового изображения путем комбинирования пикселей двух входных изображений с использованием линейной комбинации. Это позволяет контролировать яркость и контраст обоих изображений, создавая таким образом новое изображение.

    Линейное объединение изображений полезно, когда необходимо сочетать информацию из двух изображений или корректировать яркость и контраст. Это может применяться для улучшения визуальной информации, а также в медицинских, научных и технических приложениях.

    В основе этого принципа лежит идея создания нового изображения на основе взвешенной суммы интенсивностей соответствующих пикселей на исходных изображениях. Эти веса (коэффициенты) определяют влияние каждого изображения на конечный результат. Как правило, коэффициенты равны единице, что обеспечивает сохранение общей яркости в результате объединения.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Применение линейного объединение для видеокадра, принятого с веб-камеры, осуществляется функцией `cv2.addWeighted()`. Ниже рассмотрен пример программы с применением этой функции.

    ```python
    import cv2

    # Захват видеопотока с камеры
    cap = cv2.VideoCapture(0)
    while True:
        # Считывание кадра из видеопотока
        ret, frame = cap.read()
        # Отразим видеокадр по горизонтали
        frame1 = cv2.flip(frame, 1)
        # Инверсия цветов всех пикселей в кадре
        frame2 = cv2.addWeighted(frame, 0.7, frame1, 0.7, 0)

        # Отображение оригинального кадра
        cv2.imshow('Original Frame', frame)
        # Отображение отраженного кадра
        cv2.imshow('Original Flip Frame', frame1)
        # Отображение модифицированного кадра
        cv2.imshow('Modified Frame', frame2)

        # Проверка на нажатие клавиши 'q' для выхода из цикла
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    # Освобождение ресурсов
    cap.release()
    cv2.destroyAllWindows()
    ```
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Рассмотрим влияние коэффициентов в строке программы `frame3 = cv2.addWeighted(frame, 0.7, frame1, 0.7, 0)`.

    В выражении коэффициенты 0.7, 0.7 и 0 используются для линейного объединения (смешивания) двух изображений: `frame` (оригинальное изображение) и `frame1` (отраженное изображение). Здесь функция отражения изображения рассматривается в качестве примера, отличного от исходного изображения. Очевидно, вместо второго изображения может быть любое изображение с любого источника.

    Первый коэффициент (alpha=0.7) для `frame`. Этот коэффициент изменяется в пределах от 0 до 1 и определяет вес оригинального изображения в итоговом смешанном изображении. Чем выше коэффициент, тем больше вклад оригинального изображения в конечный результат. Здесь 0.7 означает, что оригинальное изображение вносит больший вклад в смешанное изображение.

    Второй коэффициент (beta=0.7) для `frame1`. Этот коэффициент изменяется в пределах от 0 до 1 и определяет вес отраженного изображения в итоговом смешанном изображении. Также чем выше коэффициент, тем больше вклад отраженного изображения в конечный результат. Здесь также 0.7, что означает, что отраженное изображение вносит существенный вклад в смешанное изображение.

    Коэффициент сдвига (gamma=0). Этот коэффициент может выступать любым вещественным числом и представляет собой сдвиг яркости. Он добавляется к взвешенной сумме интенсивностей пикселей. В данном случае, поскольку коэффициент равен 0, сдвига яркости не происходит.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""_**Зачем нужно линейное объединение?**_ Его применяют в случаях коррекции изображения при наличии нескольких снимков, что позвляет получить итоговое иозбражение более констранстным и с улучшенное детализацией. В целом этот метод применяется тогда, когда необходимо получить более целостную картину об окружающей обстановке или объекте исследования, имея несколко источников видеоинформации.""")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// admonition | ✏️ **ЗАДАНИЕ 2.**
    Написать программу которая выводит видеопоток и эффектом "змейки кадров". На текущем кадре должны оставаться следы от предыдущих кадров, тогда при движении объектов они буду оставлять за собой траекторный след. Вам потребуется в каждой итерации цикла выполнять линейное объединение текущего кадра с предыдущим (также можно с 2-3 прошлыми кадрами).
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ### 3.3/ **Вычисление абсолютной разницы изображений**

    Когда мы вычисляем абсолютную разность между двумя изображениями, мы вычисляем разницу между соответствующими пикселями каждого изображения. Например, если у нас есть два пикселя с значениями 100 и 150, то абсолютная разность между ними будет 50. Мы делаем это для каждой пары пикселей из двух изображений.

    В библиотеке OpenCV для реализации абсолютной разности двух изображений применяется функция `cv2.absdiff()`. Она принимает два изображения в качестве входных данных и возвращает новое изображение, в котором каждый пиксель представляет абсолютную разность между соответствующими пикселями входных изображений.

    Представим, у нас есть два кадра видео, мы хотим определить, где произошли изменения между ними. Мы можем использовать `cv2.absdiff()` для вычисления разницы между этими двумя кадрами. Результат будет изображением, на котором выделены области, где значения пикселей отличаются между кадрами. Когда мы применяем `cv2.absdiff()` к двум статичным изображениям, то получим прочто черное изображение. Это означает отсуствие изменения между кадрами. 

    В случае, когда у нас есть два похожих, но не совсем одинаковых изображения, мы ожидаем, что `cv2.absdiff()` выделит области, где произошли изменения. На выходе мы увидим выделенные области, которые указывают на места, где произошли изменения между изображениями.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Ниже приведен простой пример программы вычисления абсолютной разницы

    ```python
    import cv2

    # Открываем видеопоток с веб-камеры (номер 0)
    cap = cv2.VideoCapture(0)
    while True:
        # Чтение кадра из видеопотока
        ret, frame1 = cap.read()
        # Чтение следующего кадра из видеопотока
        ret, frame2 = cap.read()
        # Применение абсолютной разницы двух изображений
        diff = cv2.absdiff(frame1, frame2)
        # Отображение оригинального кадра
        cv2.imshow("FRAME1", frame1)
        # Отображение следующего кадра
        cv2.imshow("FRAME2", frame2)
        # Отображение разницы
        cv2.imshow("DIFF", diff)

        if cv2.waitKey(1) == ord('q'):
            break
    # Освобождение видеопотока
    cap.release()
    cv2.destroyAllWindows()  # Закрытие всех окон OpenCV
    ```

    В данной программе просиходит постоянное в цикле вычитание разницы между текущим и последующим кадрами. Запустите этот код. Совершите движение камерой и наблюдайте изменения. Вы получите интересный эффекто разностного изображения, когда при малейшим изменении будут подсвечиваться движущиеся объекты.

    /// attention | Вывод ☝️
    Таким образом, вычисление абсолютной разницы `cv2.absdiff()` применяется для определения движущихся объектов на изображении. Это может быть полезно при обнаружении объектов в системах видеонаблюдения, анализ тректорий объектов. В целеом этот метод применяется для анализа динамических сцен
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// admonition | ✏️ **ЗАДАНИЕ 3.**
    Напишите программу для обнаружения движения объектов. Вам потребуется доработать базовый код с `cv2.absdiff()` предложенный выше, добавив внего выделение объектов по уровню яркости (_см. Лабораторную работу №2_). Таким образом, соединив два подхода, получим более "чистое" выделение движущихся объектов.
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Форма отчета

        Отчет должен представлять собой программный код для всех заданий и скриншоты экрана, демонстрирующие работоспособоность вашего кода. Отчет загрузить на **moodle**
    """
    )
    return


if __name__ == "__main__":
    app.run()
