import marimo

__generated_with = "0.16.0"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell
def _(mo):
    mo.md(
        r"""
    # Л10: Распознавание объектов. Признаки Хаара

    **CV (Computer Vision)**, или *машинное зрение*, — это область искусственного интеллекта, которая занимается разработкой алгоритмов и методов, позволяющих компьютерам "видеть" и интерпретировать изображения и видео. Основная задача компьютерного зрения — автоматическое извлечение полезной информации из визуальных данных, например, распознавание объектов, определение их местоположения или анализ сцен. Это может включать такие приложения, как автоматизация вождения, распознавание лиц и обработка медицинских изображений.

    **OpenCV (Open Source Computer Vision Library)** — библиотека алгоритмов компьютерного зрения, обработки изображений и численных алгоритмов общего назначения с открытым кодом

    **Распознавание объектов** – это одна из ключевых задач компьютерного зрения, целью которой является определение, какие объекты присутствуют на изображении или видео, и, в некоторых случаях, где они расположены. Это фундаментальная задача, которая лежит в основе множества приложений, от систем безопасности и автономного вождения до медицинской диагностики и анализа изображений. В отличие от простой классификации изображений, когда мы определяем, что изображено на картинке в целом (например, кошка или собака), распознавание объектов требует более детального анализа, включая локализацию объектов на изображении и их классификацию по типам.

    **Признаки Хаара** (Haar-like features) — это набор прямоугольных признаков, используемых в компьютерном зрении для описания изображений.
    Они были предложены Полом Вислой и Майклом Джонсом в их работе
    по распознаванию лиц и стали ключевым элементом алгоритма каскадов Хаара,
    который до сих пор широко применяется в различных приложениях.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ☝️ПОРЯДОК ВЫПОЛНЕНИЯ

    ЛР выполняется последователньно. По мере продвижения по работе вы будете получать задания для закрепления прочитанной теории

    ✏️ **ЗАДАНИЕ 1.**
    ✏️ **ЗАДАНИЕ 2.** и т.д.

    Для каждого задания создается отдельный скрипт Python. Всего заданий будет 4. В качестве отчета необходимо предоставить файлы кода для каждого задания. Отчет закреплять на moodle.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 1/ Подготовка среды выполнения
    На данной этапе вам наобходимо подготовить виртуальное окружение и установить все необходимые библиотеки.

    1. Создать и активировать (или только активировать, если ранне создавали) виртуальной окружение `python`.

    Создайте на диске свою раюочую папку. Откройте терминал и перейдите в свою рабочую директорию
    ```
    cd path/to/your/workspace
    ```
    Далее создаем виртуальное окружение с помощью `python-venv`
    ```
    python -m venv env
    ```
    *активируем виртуальное окружение*
    для Windows (CMD, PS):
    ```
    env\Scripts\activate
    ```
    для Linux (bash)
    ```
    source env/bin/activate
    ```
    **Примечание.** `env` - это название вашего виртуального окружения, назвать его можете как угодно.

    После этого можем выбрать наш локальный интерпрететор pyhton, нажав на кнопку выше "Select kernel".

    1. Устанавливаем все необходимые библиотеки

    **Примечание.** Библиотеки установятся внутрь вашего виртуального окружения.

    Нам понадобятся `opencv-python`.
    ```
    pip install opencv-python
    ```
    И `marimo` для для просмотра интерактивной лабораторной работы
    ```
    pip install marimo
    ```
    _но вы должны были ее установить уже до открытия этого приложения_
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 2/ Получение видеопотока

    Вы можете использовать три варианта получения видеопотока: **со встроенной или подключенной камере к вашему ноутбуку, из видеофайла или из локальной сети на занятии в аудитории.**

    /// details | Код для случая видеокамеры или видеофайла
    ```python
    import cv2

    # Захватываем видеопоток с веб-камеры
    cap = cv2.VideoCapture(0)
    # или из файла
    # cap = cv2.VideoCapture('video.mp4')
    while True:
        # Читаем кадр с камеры
        ret, frame = cap.read()
        # Отображаем кадр на экране
        cv2.imshow('WebCam', frame)
        # Ожидание 1 миллисекунды на проверку нажатия клавиши 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Освобождаем ресурсы после завершения работы
    cap.release()
    # Закрываем все окна
    cv2.destroyAllWindows()
    ```
    ///

    Для получения **видеопотока по локальной сети** необходимо создать UDP сокет и подключится к multicast группе. В главном цикле читается байтовый массив по сокету, который преобразуется в jpeg-кадр. Ниже представлен базоый скрипт клиента получения видеопотока:

    /// details | Код клиента
    ```python
    import socket
    import cv2
    import numpy as np

    # Настройки multicast
    MCAST_GRP = '239.1.1.1'
    MCAST_PORT = 5007

    ############### ВМЕСТО cap = cv2.VideoCapture(0) ####################
    #####################################################################
    # Создаем UDP сокет
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

    # Присоединяемся к multicast группе
    sock.bind(('', MCAST_PORT))
    mreq = socket.inet_aton(MCAST_GRP) + socket.inet_aton('0.0.0.0')
    sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
    #####################################################################

    # Главный цикл
    while True:
    ############### ВМЕСТО ret, frame = cap.read() ######################
    #####################################################################
        # Получаем данные
        data, addr = sock.recvfrom(65536)  # Макс размер UDP пакета

        # Декодируем JPEG в изображение
        nparr = np.frombuffer(data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    #####################################################################

        if frame is not None:s
            cv2.imshow('Multicast Stream', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cv2.destroyAllWindows()
    sock.close()
    ```
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 3/ **Введение в признаки Хаара**

    Признаки Хаара основаны на идее вычисления разницы между суммой пикселей в разных прямоугольных областях изображения. Эти прямоугольные области могут быть расположены горизонтально, вертикально или под углом друг к другу. На практике используются различные типы признаков Хаара, но их объединяет один общий принцип: вычисление разницы между суммами пикселей в соседних прямоугольниках.

    Для полного понимания алгоритма Хаара необходим рассмотреть, как происходит распознавания того или иного объекта изображении.

    Для этого используются признаки Хаара (также их называют окна Хаара или фильтры Хаара). Признаки Хаара представляют собой окна различных размеров и форм, которые перемещаются по изображению. Эти признаки представляют собой простые шаблоны, которые измеряют различия в яркости между смежными областями изображения. Примерами признаков Хаара могут быть прямоугольные окна, покрывающие области с разными сочетаниями светлых и темных пикселей (см. рис. ниже).
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ![](public\image_4.png)
    Примеры набора фильтров Хаара
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""Алгоритм Хаара использует этот набор прямоугольных черно-белых областей, называемых фильтрами Хаара, которые представляют собой шаблоны для выявления текстур и форм объектов на изображениях. При сканировании изображения каждый фильтр Хаара оценивает сходство текущей области с образцом, представленным фильтром. Затем для каждой области изображения алгоритм вычисляет разницу между суммой яркостей пикселей в белой и черной областях фильтра, формируя признаки для определения объектов. Применяется пороговое значение, чтобы определить, является ли область объектом интереса. Области, которые превышают порог, считаются объектами и объединяются для получения более точной информации о расположении и форме объекта.""")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Для выделения, например, человеческого лица с помощью алгоритма Хаара, можно использовать различные признаки, которые характеризуют особенности лиц:

    _Глаза_. Обычно представляются как относительно темные области в верхней части лица с более светлой областью вокруг них. Фильтры Хаара могут обнаруживать глаза по наличию вертикальных границ между более светлыми и темными областями.

    _Нос_. Обычно представлен яркой областью между глазами, но ниже них. Фильтры Хаара могут выявлять нос по наличию горизонтальной границы между более светлой областью над носом и более темной областью под носом. Также по всей длине носа вертикально светлая часть, а по бокам от носа – вертикальные темные части.

    _Рот_. Представлен яркой областью ниже носа. Фильтры Хаара могут выявлять рот по наличию горизонтальной границы между более светлой областью над ртом и более темной областью под ртом.

    _Брови_. Обычно представлены темными областями над глазами. Фильтры Хаара могут выявлять брови по наличию горизонтальной границы между более темной областью бровей и более светлой областью лба.

    _Лицевые контуры_. Контур лица может быть выделен с помощью фильтров, которые обнаруживают границы между лицом и фоном, например, границы между лицом и волосами или между лицом и шеей.

    На рисунке ниже приведен пример распределение фильтров Хаара на изображении с лицом.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ![](public\image_5.png)
    Фильтры Хаара на изображении
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Представьте, что у нас есть фильтр Хаара, который представляет собой прямоугольную область. Этот фильтр выделяет горизонтальный светлый участок, соответствующий глазам, и более темный участок ниже, который соответствует нижней части глаза. Когда этот фильтр применяется к изображению лица, он скользит по изображению, и для каждой области вычисляется разница между суммой яркостей пикселей в черных и белых областях фильтра. Если область содержит глаза, то разница в яркости между верхней и нижней частями области будет заметной. Верхняя часть обычно светлее из-за белка глаза или выпуклости глазного яблока, а нижняя – темнее из-за тени под глазами и глазной впадины. Это приводит к высокому значению признака для этой области, что может быть интерпретировано алгоритмом как наличие глаза.

    Таким образом, фильтры Хаара, анализируя различия в яркости в разных частях области, могут помочь выявить особенности, характерные для лица человека, такие как глаза, брови и нос.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Одним из **главных преимуществ** алгоритма Хаара является его вычислительная эффективность. Простота признаков Хаара и использование интегрального изображения позволяют быстро вычислять значения признаков, что делает его подходящим для приложений, работающих в реальном времени. Это особенно важно в сценах, где требуется высокая скорость обработки, например, в системах видеонаблюдения или робототехнике. Кроме того, каскадная структура классификатора, обучаемого на основе признаков Хаара, позволяет отсеивать большую часть фоновых областей на ранних этапах, дополнительно повышая скорость работы алгоритма. Еще одним плюсом является относительно небольшое количество обучающих данных, необходимых для создания работоспособного классификатора, что делает его более доступным для использования в условиях ограниченных ресурсов.

    **Основным недостатком** алгоритма Хаара является его ограниченная способность к обнаружению сложных объектов. Поскольку признаки Хаара основаны на простых прямоугольных шаблонах, они могут быть неэффективными при распознавании объектов со сложной формой, текстурой или переменными условиями освещения. Кроме того, алгоритм Хаара может быть чувствителен к поворотам и масштабированию объектов, что требует дополнительной обработки. Также следует отметить, что алгоритм каскадов Хаара, хотя и эффективен для задач обнаружения объектов, может уступать по точности более современным методам глубокого обучения, особенно при распознавании сложных и многовариантных объектов. Поэтому выбор алгоритма Хаара может быть нецелесообразным при необходимости высокой точности и надежности в сложных условиях.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 4/ **Применение каскадов Хаара**

    Одним из основных методов распознавания объектов в библиотеке OpenCV является использование **каскадов Хаара**. Этот метод основан на поиске характерных признаков объекта на изображении, таких как края, углы или текстуры. Классификаторы Хаара представляют собой набор шаблонов, которые обучаются на большом количестве положительных и отрицательных примеров объектов.

    Процесс распознавания объектов с использованием OpenCV обычно включает в себя следующие шаги:

    1. Загрузка изображения или видеопотока с камеры.
    2. Преобразование изображения в формат, подходящий для обработки.
    3. Применение классификатора или модели, обученной на определенном типе объектов.
    4. Обнаружение объектов на изображении или видео.
    5. Отображение результатов распознавания, например, путем обведения обнаруженных объектов прямоугольниками или другими маркерами.
    6. Дополнительная обработка результатов, если это необходимо, например, определение дополнительных характеристик объектов или их классификация.

    В результате успешного распознавания объектов можно получить информацию о их положении, размере, форме, а также сделать выводы о том, какие объекты присутствуют на изображении или в видеопотоке.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Для использования классификатора Хаара в OpenCV сначала нужно загрузить предварительно обученный классификатор с диска или из библиотеки OpenCV, а затем применить его к изображению или кадру видео. Этот процесс может быть выполнен с помощью функции `detectMultiScale()`. Эта функция позволяет обнаружить объекты различного размера на изображении.

    После применения классификатора на изображении мы получаем координаты `(x, y, w, h)` прямоугольника, который описывает обнаруженный объект. Здесь `(x, y)` — это координаты верхнего левого угла прямоугольника, а `(w, h)` — его ширина и высота соответственно.

    Ниже рассмотрим пример программы применения алгоритма Хаара, который обнаруживает лицо человека на изображении.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ```python
    import cv2

    # Загрузка предварительно обученных классификаторов для лица и глаз
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    # Считывание изображение
    imgeg = cv2.imread("image.jpg")
    # Преобразование кадра в оттенки серого
    gray = cv2.cvtColor(imgeg, cv2.COLOR_BGR2GRAY)
    # Поиск лиц в кадре
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    # Отрисовка прямоугольника вокруг обнаруженных лиц
    for (x, y, w, h) in faces:
        cv2.rectangle(imgeg, (x, y), (x+w, y+h), (255, 0, 0), 2)

    # Отображение результата
    cv2.imshow('Faces', imgeg)
    # Выход из цикла
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    ```
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Программа загружает предварительно обученный классификатор для обнаружения лиц, считывает изображение, преобразует его в оттенки серого, затем использует классификатор для обнаружения лиц на изображении. После обнаружения лиц программа отрисовывает прямоугольники вокруг каждого обнаруженного лица и выводит полученное изображение с прямоугольниками на экран.

    Остановимся на отдельных строках программы.

    Строка

    ```python
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    ```

    инициализирует переменную `face_cascade`, используя предварительно обученный классификатор для обнаружения лиц. Она объединяет путь к каталогу с предварительно обученными моделями каскадов Хаара (`cv2.data.haarcascades`) с именем файла XML для обнаружения лиц в передней части (`haarcascade_frontalface_default.xml`). То есть данный классификатор обучен распознавать лица, находящиеся в положении, когда они повернуты к камере лицом, а не в профиль или в других нестандартных позах.

    В каталоге `cv2.data.haarcascades` обычно содержатся несколько предварительно обученных моделей каскадов Хаара для обнаружения различных объектов. Наиболее распространённые модели включают в себя:

    - `haarcascade_eye.xml`: модель для обнаружения глаз;
    - `haarcascade_frontalface_alt.xml`: вариант модели для обнаружения лиц в передней позе (альтернативный);
    - `haarcascade_smile.xml`: модель для обнаружения улыбок;
    - `haarcascade_upperbody.xml`: модель для обнаружения верхней части тела;
    - `haarcascade_fullbody.xml`: модель для обнаружения полного тела;
    - `haarcascade_profileface.xml`: модель для обнаружения лиц в профиль;
    - `haarcascade_eye_tree_eyeglasses.xml`: модель для обнаружения глаз с очками.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Стоит заметить, что это далеко не полный список моделей, представленных в каталоге `cv2.data.haarcascades`.

    Результат выполнения такой программы показан на рис. 7.7.

    Строка

    ```python
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    ```

    выполняет обнаружение объектов на изображении с использованием классификатора каскадов Хаара, который был предварительно обучен для обнаружения лиц.

    `gray` – это изображение в оттенках серого, на котором мы ищем объекты (в данном случае, лица).

    `1.3` – это параметр `scaleFactor`, который определяет, насколько изображение уменьшается на каждом шаге при масштабировании изображения для поиска объектов. Например, если это значение равно 1.3, то изображение будет уменьшено на 30 % на каждом шаге.

    `5` – это параметр `minNeighbors`, который определяет, сколько соседних прямоугольников должно быть обнаружено, чтобы считать обнаруженный объект действительным. Увеличение этого значения приводит к более консервативной фильтрации объектов, уменьшая количество ложных срабатываний.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// admonition | ✏️ **ЗАДАНИЕ 1.**
    Адаптируйте пример кода выше по обработку видеопотока.

    Исследуйте обнаружение нескольких объектов, используя различные классификаторы Хаара. Опробуйте различные предварительно обученных классификаторов (например, для глаз, улыбок, тел людей) и напишите программу, которая последовательно применяет их к кадру видео. Отобразите результаты, выделяя каждый тип обнаруженного объекта разными цветами или маркерами. Проанализируйте, как разные классификаторы работают на одном и том же изображении и какие типы объектов они могут успешно обнаружить.
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// admonition | ✏️ **ЗАДАНИЕ 2.**
    Проведите эксперимент с параметрами функции `detectMultiScale()`, используемой для обнаружения объектов. Загрузите изображение или видео и, используя один из классификаторов, изменяйте значения параметров `scaleFactor`, `minNeighbors`, `minSize` и `maxSize`. Наблюдайте и записывайте, как меняется количество и качество обнаруженных объектов при изменении каждого параметра. Сделайте выводы о том, какие параметры наиболее важны для успешного обнаружения и как их можно настроить для достижения наилучших результатов в конкретных условиях.
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Форма отчета

    Отчет должен представлять собой программный код для всех заданий и скриншоты экрана, демонстрирующие работоспособоность вашего кода. Отчет загрузить на **moodle**
    """
    )
    return


if __name__ == "__main__":
    app.run()
