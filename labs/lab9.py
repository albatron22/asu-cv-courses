import marimo

__generated_with = "0.16.0"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    # Л9: Распознавание объектов. Поиск объектов с помощью сопоставления шаблонов

    **CV (Computer Vision)**, или *машинное зрение*, — это область искусственного интеллекта, которая занимается разработкой алгоритмов и методов, позволяющих компьютерам "видеть" и интерпретировать изображения и видео. Основная задача компьютерного зрения — автоматическое извлечение полезной информации из визуальных данных, например, распознавание объектов, определение их местоположения или анализ сцен. Это может включать такие приложения, как автоматизация вождения, распознавание лиц и обработка медицинских изображений.

    **OpenCV (Open Source Computer Vision Library)** — библиотека алгоритмов компьютерного зрения, обработки изображений и численных алгоритмов общего назначения с открытым кодом

    **Распознавание объектов** – это одна из ключевых задач компьютерного зрения, целью которой является определение, какие объекты присутствуют на изображении или видео, и, в некоторых случаях, где они расположены. Это фундаментальная задача, которая лежит в основе множества приложений, от систем безопасности и автономного вождения до медицинской диагностики и анализа изображений. В отличие от простой классификации изображений, когда мы определяем, что изображено на картинке в целом (например, кошка или собака), распознавание объектов требует более детального анализа, включая локализацию объектов на изображении и их классификацию по типам.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## ☝️ПОРЯДОК ВЫПОЛНЕНИЯ

    ЛР выполняется последователньно. По мере продвижения по работе вы будете получать задания для закрепления прочитанной теории

    ✏️ **ЗАДАНИЕ 1.**
    ✏️ **ЗАДАНИЕ 2.** и т.д.

    Для каждого задания создается отдельный скрипт Python. Всего заданий будет 4. В качестве отчета необходимо предоставить файлы кода для каждого задания. Отчет закреплять на moodle.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 1/ Подготовка среды выполнения
    На данной этапе вам наобходимо подготовить виртуальное окружение и установить все необходимые библиотеки.

    1. Создать и активировать (или только активировать, если ранне создавали) виртуальной окружение `python`.

    Создайте на диске свою раюочую папку. Откройте терминал и перейдите в свою рабочую директорию
    ```
    cd path/to/your/workspace
    ```
    Далее создаем виртуальное окружение с помощью `python-venv`
    ```
    python -m venv env
    ```
    *активируем виртуальное окружение*
    для Windows (CMD, PS):
    ```
    env\Scripts\activate
    ```
    для Linux (bash)
    ```
    source env/bin/activate
    ```
    **Примечание.** `env` - это название вашего виртуального окружения, назвать его можете как угодно.

    После этого можем выбрать наш локальный интерпрететор pyhton, нажав на кнопку выше "Select kernel".

    1. Устанавливаем все необходимые библиотеки

    **Примечание.** Библиотеки установятся внутрь вашего виртуального окружения.

    Нам понадобятся `opencv-python`.
    ```
    pip install opencv-python
    ```
    И `marimo` для для просмотра интерактивной лабораторной работы
    ```
    pip install marimo
    ```
    _но вы должны были ее установить уже до открытия этого приложения_
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 2/ Получение видеопотока

    Вы можете использовать три варианта получения видеопотока: **со встроенной или подключенной камере к вашему ноутбуку, из видеофайла или из локальной сети на занятии в аудитории.**

    /// details | Код для случая видеокамеры или видеофайла
    ```python
    import cv2

    # Захватываем видеопоток с веб-камеры
    cap = cv2.VideoCapture(0)
    # или из файла
    # cap = cv2.VideoCapture('video.mp4')
    while True:
        # Читаем кадр с камеры
        ret, frame = cap.read()
        # Отображаем кадр на экране
        cv2.imshow('WebCam', frame)
        # Ожидание 1 миллисекунды на проверку нажатия клавиши 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Освобождаем ресурсы после завершения работы
    cap.release()
    # Закрываем все окна
    cv2.destroyAllWindows()
    ```
    ///

    Для получения **видеопотока по локальной сети** необходимо создать UDP сокет и подключится к multicast группе. В главном цикле читается байтовый массив по сокету, который преобразуется в jpeg-кадр. Ниже представлен базоый скрипт клиента получения видеопотока:

    /// details | Код клиента
    ```python
    import socket
    import cv2
    import numpy as np

    # Настройки multicast
    MCAST_GRP = '239.1.1.1'
    MCAST_PORT = 5007

    ############### ВМЕСТО cap = cv2.VideoCapture(0) ####################
    #####################################################################
    # Создаем UDP сокет
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

    # Присоединяемся к multicast группе
    sock.bind(('', MCAST_PORT))
    mreq = socket.inet_aton(MCAST_GRP) + socket.inet_aton('0.0.0.0')
    sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
    #####################################################################

    # Главный цикл
    while True:
    ############### ВМЕСТО ret, frame = cap.read() ######################
    #####################################################################
        # Получаем данные
        data, addr = sock.recvfrom(65536)  # Макс размер UDP пакета

        # Декодируем JPEG в изображение
        nparr = np.frombuffer(data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    #####################################################################

        if frame is not None:s
            cv2.imshow('Multicast Stream', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cv2.destroyAllWindows()
    sock.close()
    ```
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 3/ **Введение в распознавание объектов**

    Традиционные методы распознавания объектов, разработанные до широкого распространения глубокого обучения, часто опираются на ручное конструирование признаков и использование классификаторов, которые обучаются на основе этих признаков. Признаки, или дескрипторы, представляют собой важные характеристики объектов, которые позволяют их различать, опираясь на такие свойства, как форма, текстура, цвет и другие визуальные особенности. Примеры таких признаков включают в себя выделение краев, углов, текстурных градиентов, а также более сложные характеристики, такие как гистограммы ориентированных градиентов (HOG) или признаки Хаара. Параллельно с этими подходами, существуют методы распознавания, основанные на сопоставлении с шаблонами. В отличие от методов, основанных на признаках, сопоставление с шаблонами не требует предварительного определения дескрипторов объекта, а основывается на непосредственном сравнении всего изображения или его фрагмента с заранее определенным шаблоном при помощи корреляционных принципов. Это означает, что вместо анализа отдельных характеристик, сопоставляется вся структура или выделенная область объекта.

    После извлечения признаков следующим шагом является обучение классификатора.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    **Классификатор** — это алгоритм, который, получив на вход вектор признаков, определяет, к какому классу относится данный объект. Классические методы используют различные алгоритмы классификации, такие как метод опорных векторов (SVM), метод k-ближайших соседей (k-NN), случайный лес или алгоритмы бустинга, такие как AdaBoost. Эти алгоритмы обучаются на наборе размеченных данных, где для каждого объекта указано, к какому классу он относится.

    Обзор традиционных методов распознавания объектов включает в себя несколько ключевых этапов. Первым шагом является предобработка изображений, которая может включать в себя изменение размера, нормализацию, удаление шума или другие операции для улучшения качества входных данных. Затем происходит извлечение признаков, когда из изображения выделяются дескрипторы, которые описывают интересующие нас объекты. После этого происходит обучение классификатора на размеченном наборе данных, чтобы модель могла правильно определять тип объекта. И наконец, классификатор используется для распознавания объектов на новых, невидимых ранее изображениях.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Одним из важных классических методов является использование дескрипторов на основе градиентов, таких как HOG. Они опираются на анализ градиентов яркости пикселей и позволяют описывать форму объектов. Другой подход использует текстурные признаки, такие как фильтры Габора, которые позволяют выделять текстуры на изображениях. Алгоритмы бустинга, такие как AdaBoost, позволяют объединять слабые классификаторы в более мощный и точный. Все эти методы, хотя и уступают в точности методам глубокого обучения, до сих пор представляют интерес благодаря своей вычислительной эффективности и интерпретируемости.

    В настоящее время, несмотря на доминирование методов глубокого обучения, классические методы распознавания объектов все еще находят свое применение в различных задачах. Это особенно актуально в тех случаях, где требуется высокая скорость вычислений или когда нет большого количества размеченных данных для обучения сложных глубоких нейросетей. Классические методы, будь то основанные на ручном конструировании признаков с последующей классификацией или на сопоставлении с шаблонами, предлагают альтернативные подходы с меньшими вычислительными затратами и зачастую с достаточной точностью для конкретных применений. Кроме того, понимание принципов работы этих алгоритмов — от выделения признаков до корреляционного сравнения шаблонов — помогает глубже понять, как вообще работает распознавание объектов, и может быть полезно для разработки более эффективных и надежных систем, а также для задач, где необходима интерпретируемость решения. Методы с признаками предполагают интерпретируемые дескрипторы объектов, а методы сопоставления шаблонов хорошо работают в условиях, когда объект имеет четко определенную форму и когда не требуется устойчивость к значительным изменениям освещения, ракурса и масштаба.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## 4/ **Поиск объектов с помощью сопоставления шаблонов**

    Шаблонный поиск — это, по сути, процесс поиска небольшого изображения (шаблона) внутри большего изображения. Этот метод основывается на сравнении шаблона с разными участками исходного изображения. Представьте, что вы наложили прозрачный шаблон на исходное изображение и сдвигаете его по всему изображению. На каждом шаге вы смотрите, насколько шаблон похож на то, что под ним находится. Если есть совпадение, значит, шаблон «найден».

    Для того чтобы компьютер мог сравнивать шаблон с изображением, ему нужно использовать какой-то метод «измерения» сходства. Наиболее распространенные методы — это сравнение по пикселям. То есть компьютер смотрит на значения яркости каждого пикселя шаблона и сравнивает их со значениями яркости соответствующего участка изображения. Чем больше совпадений, тем выше сходство.

    При сравнении используется не просто разница значений, но и различные математические функции, которые позволяют учесть некоторые особенности изображений, такие как яркость, контрастность и т. д. Например, метод нормализованной корреляции используется для того, чтобы сравнение было более устойчивым к изменениям освещения. **Корреляция** в данном контексте — это показатель того, насколько похожи друг на друга сравниваемые области изображения. Другие методы, такие как суммы квадратов разностей, ориентированы на нахождение точных совпадений, но более чувствительны к шуму.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""Функция `cv2.matchTemplate()`, которая предоставляется библиотекой OpenCV, реализует этот процесс. Она принимает на вход исходное изображение, шаблон и один из методов сравнения. На выходе она возвращает матрицу, в которой значения соответствуют степени сходства шаблона с каждым участком исходного изображения. Эта матрица показывает карту соответствия шаблона в изображении.""")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Однако шаблонный поиск не является идеальным решением и имеет свои ограничения. Он хорошо работает, когда искомый объект имеет четкие контуры и не меняет свой размер, ориентацию или освещение. Любые изменения в масштабе, повороте или освещении могут привести к тому, что шаблон не будет найден. Поэтому в реальных задачах перед использованием шаблонного поиска часто требуется предобработка изображений.

    Тем не менее шаблонный поиск остается очень полезным инструментом в компьютерном зрении. Он применяется в различных областях — от контроля качества в производстве до автоматизированного поиска объектов на изображениях и видео. Простота и эффективность сделали его популярным и базовым методом, который важно знать каждому, кто изучает компьютерное зрение.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Теперь, когда у нас есть общее понимание шаблонного поиска, давайте углубимся в детали и рассмотрим методы, которые применяются в функции `cv2.matchTemplate()`. Эти методы определяют, как именно происходит сравнение шаблона с исходным изображением.

    **Методы сравнения в cv2.matchTemplate():**

    1.  **Сумма квадратов разностей (cv2.TM_SQDIFF)** – этот метод вычисляет сумму квадратов разностей между значениями пикселей шаблона и соответствующей области изображения. Для каждой пары пикселей разница их значений возводится в квадрат, и затем все квадраты суммируются. Результатом является скалярное значение, которое характеризует степень несовпадения: чем меньше эта сумма, тем выше сходство между шаблоном и исследуемой областью изображения. Важно отметить, что метод `cv2.TM_SQDIFF` не является нормализованным, поэтому он чувствителен к изменениям яркости изображения.

    2.  **Нормализованная сумма квадратов разностей (cv2.TM_SQDIFF_NORMED)** – является нормализованной версией `cv2.TM_SQDIFF`. После вычисления суммы квадратов разностей, результат дополнительно делится на произведение норм вектора значений пикселей шаблона и вектора значений пикселей исследуемой области изображения. Такая нормализация делает метод более устойчивым к изменениям яркости и контрастности, так как снижает влияние абсолютных значений интенсивности пикселей. Как и в случае с `cv2.TM_SQDIFF`, наименьшее значение свидетельствует о наилучшем соответствии.

    3.  **Кросс-корреляция (cv2.TM_CCORR)** – метод, использующий операцию кросс-корреляции, которая вычисляет меру сходства между двумя сигналами. В контексте изображений это означает скалярное произведение между вектором значений пикселей шаблона и вектором значений пикселей исследуемой области изображения. Положительные высокие значения указывают на наличие схожих структур. Важно, что данный метод, в отличие от `cv2.TM_SQDIFF`, максимизирует результат и не нормализован, поэтому подвержен влиянию различий в освещенности.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Нормализованная кросс-корреляция (`cv2.TM_CCOEFF_NORMED`) является нормализованной версией метода `cv2.TM_CCORR`. После вычисления кросс-корреляции результат делится на произведение норм векторов значений пикселей шаблона и области изображения. Такая нормализация приводит к тому, что метод становится более инвариантным к изменениям яркости и контрастности. Наивысшее значение на карте сопоставления соответствует наилучшему совпадению.

    Коэффициент корреляции (`cv2.TM_CCOEFF`) вычисляет коэффициент корреляции Пирсона между вектором значений пикселей шаблона и вектором значений пикселей области изображения. Коэффициент корреляции является статистической мерой линейной взаимосвязи между двумя переменными. В этом случае коэффициент корреляции измеряет степень схожести формы и структуры шаблона и области, даже если они могут отличаться по среднему уровню яркости.

    Нормализованный коэффициент корреляции (`cv2.TM_CCOEFF_NORMED`) представляет собой собой нормализованную версию метода `cv2.TM_CCOEFF`. После вычисления коэффициента корреляции результат масштабируется, что делает метод более устойчивым к изменениям контраста и яркости. Нормализованный коэффициент корреляции принимает значения от -1 до 1, где 1 соответствует полному совпадению, 0 — отсутствию корреляции, а -1 — полной антикорреляции.

    Ниже представлен пример реализации программы поиска объектов с помощью сопоставления шаблонов.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ```python
    import cv2
    import numpy as np

    # Загрузка изображений
    image = cv2.imread('Main.jpg', cv2.IMREAD_COLOR)
    template = cv2.imread('Pattern.jpg', cv2.IMREAD_COLOR)

    # Преобразование в оттенки серого
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)

    # Применение шаблонного поиска (выберем метод cv2.TM_CCOEFF_NORMED)
    result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)

    # Поиск координат наилучшего соответствия
    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)

    # Определение координат шаблона
    top_left = max_loc
    h, w = gray_template.shape
    bottom_right = (top_left[0] + w, top_left[1] + h)

    # Отрисовка прямоугольника на изображении
    cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)

    # Отображение результата
    cv2.imshow('Res', image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    ```

    Эта программа предназначена для поиска определенного объекта на изображении. Сначала программа загружает два изображения: `Main.jpg`, например, представляющее панораму города, и `Pattern.jpg`, представляющее шаблон объекта (например здания), который нужно найти (ниже на рисунке). Далее, для упрощения вычислений и повышения точности, оба изображения конвертируются из цветного формата в оттенки серого.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""![](public\image_2.png)""")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Затем программа применяет функцию `cv2.matchTemplate()` с методом `cv2.TM_CCOEFF_NORMED`, который вычисляет нормализованный коэффициент корреляции между шаблоном и разными областями панорамы. Результатом является карта, где каждое значение показывает степень сходства шаблона с соответствующей областью панорамы. Функция `cv2.minMaxLoc()` находит координаты точки на карте результатов, где сходство наибольшее (максимальное значение для этого метода корреляции).

    Используя координаты наилучшего соответствия, программа определяет верхний левый угол найденного объекта на панораме. Затем, используя ширину и высоту шаблона, программа вычисляет координаты нижнего правого угла. Эти координаты необходимы для отрисовки прямоугольника, который выделит найденный объект на изображении панорамы города. Прямоугольник будет нарисован зеленым цветом с толщиной линии 2 пикселя.

    Результат работы программы представлен ниже.
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""![](public\image_3.png)""")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// admonition | ✏️ **ЗАДАНИЕ 1.**
    Разработайте программу, которая использует сохраненный фрагмент вашего лица (например область глаз) для поиска этого шаблона в видеопотоке с вебкамеры. Найденный фрагмент должен выделятся прямоугольником. 

    Используйте пример кода выше, но адаптируйте его под обработку видеопотока с вебкамеры. 

    Покажите работу программы с различными методами шаблонного поиска и проанализируйте их влияние на результат.
    ///
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Форма отчета

    Отчет должен представлять собой программный код для всех заданий и скриншоты экрана, демонстрирующие работоспособоность вашего кода. Отчет загрузить на **moodle**
    """
    )
    return


if __name__ == "__main__":
    app.run()
